{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43dd4436",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "import pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "604c74cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b1e3fc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/Users/asrana/opt/anaconda3/lib/python3.9/site-packages/pyspark/jars/spark-unsafe_2.12-3.2.1.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/01/23 11:28:55 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName('pySpark Visualisation').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "984e6aea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://10.140.8.5:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.2.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pySpark Visualisation</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7fe5183a90d0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4b4ba7f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    }
   ],
   "source": [
    "print(\"ok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a0e4852f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "907d3336",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EI_DJTA_20160128_Trades.csv       newData_timeSeries.ipynb\r\n",
      "Iris.csv                          pySpark_Iris_Visualisation.ipynb\r\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fd9b9e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataDF = spark.read.csv(\"Iris.csv\",header= True, inferSchema= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c78fbede",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------+------------+-------------+------------+-----------+\n",
      "|Id |SepalLengthCm|SepalWidthCm|PetalLengthCm|PetalWidthCm|Species    |\n",
      "+---+-------------+------------+-------------+------------+-----------+\n",
      "|1  |5.1          |3.5         |1.4          |0.2         |Iris-setosa|\n",
      "|2  |4.9          |3.0         |1.4          |0.2         |Iris-setosa|\n",
      "|3  |4.7          |3.2         |1.3          |0.2         |Iris-setosa|\n",
      "|4  |4.6          |3.1         |1.5          |0.2         |Iris-setosa|\n",
      "|5  |5.0          |3.6         |1.4          |0.2         |Iris-setosa|\n",
      "|6  |5.4          |3.9         |1.7          |0.4         |Iris-setosa|\n",
      "|7  |4.6          |3.4         |1.4          |0.3         |Iris-setosa|\n",
      "|8  |5.0          |3.4         |1.5          |0.2         |Iris-setosa|\n",
      "|9  |4.4          |2.9         |1.4          |0.2         |Iris-setosa|\n",
      "|10 |4.9          |3.1         |1.5          |0.1         |Iris-setosa|\n",
      "|11 |5.4          |3.7         |1.5          |0.2         |Iris-setosa|\n",
      "|12 |4.8          |3.4         |1.6          |0.2         |Iris-setosa|\n",
      "|13 |4.8          |3.0         |1.4          |0.1         |Iris-setosa|\n",
      "|14 |4.3          |3.0         |1.1          |0.1         |Iris-setosa|\n",
      "|15 |5.8          |4.0         |1.2          |0.2         |Iris-setosa|\n",
      "|16 |5.7          |4.4         |1.5          |0.4         |Iris-setosa|\n",
      "|17 |5.4          |3.9         |1.3          |0.4         |Iris-setosa|\n",
      "|18 |5.1          |3.5         |1.4          |0.3         |Iris-setosa|\n",
      "|19 |5.7          |3.8         |1.7          |0.3         |Iris-setosa|\n",
      "|20 |5.1          |3.8         |1.5          |0.3         |Iris-setosa|\n",
      "+---+-------------+------------+-------------+------------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataDF.show(truncate= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fef63544",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Id: integer (nullable = true)\n",
      " |-- SepalLengthCm: double (nullable = true)\n",
      " |-- SepalWidthCm: double (nullable = true)\n",
      " |-- PetalLengthCm: double (nullable = true)\n",
      " |-- PetalWidthCm: double (nullable = true)\n",
      " |-- Species: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataDF.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "75ee4fad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150 6\n"
     ]
    }
   ],
   "source": [
    "# shape of dataFrame - \n",
    "print(dataDF.count(),len(dataDF.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ebb511fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+------------------+-------------------+------------------+------------------+--------------+\n",
      "|summary|                Id|     SepalLengthCm|       SepalWidthCm|     PetalLengthCm|      PetalWidthCm|       Species|\n",
      "+-------+------------------+------------------+-------------------+------------------+------------------+--------------+\n",
      "|  count|               150|               150|                150|               150|               150|           150|\n",
      "|   mean|              75.5| 5.843333333333335| 3.0540000000000007|3.7586666666666693|1.1986666666666672|          null|\n",
      "| stddev|43.445367992456916|0.8280661279778637|0.43359431136217375| 1.764420419952262|0.7631607417008414|          null|\n",
      "|    min|                 1|               4.3|                2.0|               1.0|               0.1|   Iris-setosa|\n",
      "|    25%|                38|               5.1|                2.8|               1.6|               0.3|          null|\n",
      "|    50%|                75|               5.8|                3.0|               4.3|               1.3|          null|\n",
      "|    75%|               113|               6.4|                3.3|               5.1|               1.8|          null|\n",
      "|    max|               150|               7.9|                4.4|               6.9|               2.5|Iris-virginica|\n",
      "+-------+------------------+------------------+-------------------+------------------+------------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# describle equivalent - \n",
    "dataDF.summary().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "36fd39e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Id: integer (nullable = true)\n",
      " |-- SepalLengthCm: double (nullable = true)\n",
      " |-- SepalWidthCm: double (nullable = true)\n",
      " |-- PetalLengthCm: double (nullable = true)\n",
      " |-- PetalWidthCm: double (nullable = true)\n",
      " |-- Species: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# info equivalent\n",
    "dataDF.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "648e5106",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'isNull'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/y6/n1sc00pn303gl4f1zd46tdk80000gq/T/ipykernel_86888/118058616.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdataDF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misNull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1657\u001b[0m         \"\"\"\n\u001b[1;32m   1658\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1659\u001b[0;31m             raise AttributeError(\n\u001b[0m\u001b[1;32m   1660\u001b[0m                 \"'%s' object has no attribute '%s'\" % (self.__class__.__name__, name))\n\u001b[1;32m   1661\u001b[0m         \u001b[0mjc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'isNull'"
     ]
    }
   ],
   "source": [
    "dataDF.isNull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bb488d21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------+------------+-------------+------------+-------+\n",
      "| Id|SepalLengthCm|SepalWidthCm|PetalLengthCm|PetalWidthCm|Species|\n",
      "+---+-------------+------------+-------------+------------+-------+\n",
      "|  0|            0|           0|            0|           0|      0|\n",
      "+---+-------------+------------+-------------+------------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#  to check for isNull() in all columns\n",
    "tempDF = dataDF.select([count(when(col(c).contains('None') \\\n",
    "                                   | col(c).contains('NULL') \\\n",
    "                                   | (col(c) == '') \\\n",
    "                                   | col(c).isNull() \\\n",
    "                                   | isnan(c),c )).alias( c) for c in dataDF.columns])\n",
    "tempDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2f1cf1df",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'Column' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/y6/n1sc00pn303gl4f1zd46tdk80000gq/T/ipykernel_86888/2591119868.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdataDF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistinct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malias\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataDF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;34m]\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/y6/n1sc00pn303gl4f1zd46tdk80000gq/T/ipykernel_86888/2591119868.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdataDF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistinct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malias\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataDF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;34m]\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'Column' object is not callable"
     ]
    }
   ],
   "source": [
    "dataDF.select([col(c).distinct().count().alias(c)  for c in dataDF.columns ] ).show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5f518070",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-----------------------------+----------------------------+-----------------------------+----------------------------+-----------------------+\n",
      "|count(DISTINCT Id)|count(DISTINCT SepalLengthCm)|count(DISTINCT SepalWidthCm)|count(DISTINCT PetalLengthCm)|count(DISTINCT PetalWidthCm)|count(DISTINCT Species)|\n",
      "+------------------+-----------------------------+----------------------------+-----------------------------+----------------------------+-----------------------+\n",
      "|               150|                           35|                          23|                           43|                          22|                      3|\n",
      "+------------------+-----------------------------+----------------------------+-----------------------------+----------------------------+-----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataDF.select([countDistinct(c) for c in dataDF.columns]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b0168724",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_names = []\n",
    "for x in dataDF.select(\"Species\").distinct().collect():\n",
    "    unique_names.append(x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "93f9fc5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Iris-virginica', 'Iris-setosa', 'Iris-versicolor']\n"
     ]
    }
   ],
   "source": [
    "print(unique_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a077ad8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tables = [dataDF.where(dataDF.Species == x) for x in unique_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8bcb26bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------+------------+-------------+------------+--------------+\n",
      "| Id|SepalLengthCm|SepalWidthCm|PetalLengthCm|PetalWidthCm|       Species|\n",
      "+---+-------------+------------+-------------+------------+--------------+\n",
      "|101|          6.3|         3.3|          6.0|         2.5|Iris-virginica|\n",
      "|102|          5.8|         2.7|          5.1|         1.9|Iris-virginica|\n",
      "|103|          7.1|         3.0|          5.9|         2.1|Iris-virginica|\n",
      "|104|          6.3|         2.9|          5.6|         1.8|Iris-virginica|\n",
      "|105|          6.5|         3.0|          5.8|         2.2|Iris-virginica|\n",
      "|106|          7.6|         3.0|          6.6|         2.1|Iris-virginica|\n",
      "|107|          4.9|         2.5|          4.5|         1.7|Iris-virginica|\n",
      "|108|          7.3|         2.9|          6.3|         1.8|Iris-virginica|\n",
      "|109|          6.7|         2.5|          5.8|         1.8|Iris-virginica|\n",
      "|110|          7.2|         3.6|          6.1|         2.5|Iris-virginica|\n",
      "|111|          6.5|         3.2|          5.1|         2.0|Iris-virginica|\n",
      "|112|          6.4|         2.7|          5.3|         1.9|Iris-virginica|\n",
      "|113|          6.8|         3.0|          5.5|         2.1|Iris-virginica|\n",
      "|114|          5.7|         2.5|          5.0|         2.0|Iris-virginica|\n",
      "|115|          5.8|         2.8|          5.1|         2.4|Iris-virginica|\n",
      "|116|          6.4|         3.2|          5.3|         2.3|Iris-virginica|\n",
      "|117|          6.5|         3.0|          5.5|         1.8|Iris-virginica|\n",
      "|118|          7.7|         3.8|          6.7|         2.2|Iris-virginica|\n",
      "|119|          7.7|         2.6|          6.9|         2.3|Iris-virginica|\n",
      "|120|          6.0|         2.2|          5.0|         1.5|Iris-virginica|\n",
      "+---+-------------+------------+-------------+------------+--------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+---+-------------+------------+-------------+------------+-----------+\n",
      "| Id|SepalLengthCm|SepalWidthCm|PetalLengthCm|PetalWidthCm|    Species|\n",
      "+---+-------------+------------+-------------+------------+-----------+\n",
      "|  1|          5.1|         3.5|          1.4|         0.2|Iris-setosa|\n",
      "|  2|          4.9|         3.0|          1.4|         0.2|Iris-setosa|\n",
      "|  3|          4.7|         3.2|          1.3|         0.2|Iris-setosa|\n",
      "|  4|          4.6|         3.1|          1.5|         0.2|Iris-setosa|\n",
      "|  5|          5.0|         3.6|          1.4|         0.2|Iris-setosa|\n",
      "|  6|          5.4|         3.9|          1.7|         0.4|Iris-setosa|\n",
      "|  7|          4.6|         3.4|          1.4|         0.3|Iris-setosa|\n",
      "|  8|          5.0|         3.4|          1.5|         0.2|Iris-setosa|\n",
      "|  9|          4.4|         2.9|          1.4|         0.2|Iris-setosa|\n",
      "| 10|          4.9|         3.1|          1.5|         0.1|Iris-setosa|\n",
      "| 11|          5.4|         3.7|          1.5|         0.2|Iris-setosa|\n",
      "| 12|          4.8|         3.4|          1.6|         0.2|Iris-setosa|\n",
      "| 13|          4.8|         3.0|          1.4|         0.1|Iris-setosa|\n",
      "| 14|          4.3|         3.0|          1.1|         0.1|Iris-setosa|\n",
      "| 15|          5.8|         4.0|          1.2|         0.2|Iris-setosa|\n",
      "| 16|          5.7|         4.4|          1.5|         0.4|Iris-setosa|\n",
      "| 17|          5.4|         3.9|          1.3|         0.4|Iris-setosa|\n",
      "| 18|          5.1|         3.5|          1.4|         0.3|Iris-setosa|\n",
      "| 19|          5.7|         3.8|          1.7|         0.3|Iris-setosa|\n",
      "| 20|          5.1|         3.8|          1.5|         0.3|Iris-setosa|\n",
      "+---+-------------+------------+-------------+------------+-----------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+---+-------------+------------+-------------+------------+---------------+\n",
      "| Id|SepalLengthCm|SepalWidthCm|PetalLengthCm|PetalWidthCm|        Species|\n",
      "+---+-------------+------------+-------------+------------+---------------+\n",
      "| 51|          7.0|         3.2|          4.7|         1.4|Iris-versicolor|\n",
      "| 52|          6.4|         3.2|          4.5|         1.5|Iris-versicolor|\n",
      "| 53|          6.9|         3.1|          4.9|         1.5|Iris-versicolor|\n",
      "| 54|          5.5|         2.3|          4.0|         1.3|Iris-versicolor|\n",
      "| 55|          6.5|         2.8|          4.6|         1.5|Iris-versicolor|\n",
      "| 56|          5.7|         2.8|          4.5|         1.3|Iris-versicolor|\n",
      "| 57|          6.3|         3.3|          4.7|         1.6|Iris-versicolor|\n",
      "| 58|          4.9|         2.4|          3.3|         1.0|Iris-versicolor|\n",
      "| 59|          6.6|         2.9|          4.6|         1.3|Iris-versicolor|\n",
      "| 60|          5.2|         2.7|          3.9|         1.4|Iris-versicolor|\n",
      "| 61|          5.0|         2.0|          3.5|         1.0|Iris-versicolor|\n",
      "| 62|          5.9|         3.0|          4.2|         1.5|Iris-versicolor|\n",
      "| 63|          6.0|         2.2|          4.0|         1.0|Iris-versicolor|\n",
      "| 64|          6.1|         2.9|          4.7|         1.4|Iris-versicolor|\n",
      "| 65|          5.6|         2.9|          3.6|         1.3|Iris-versicolor|\n",
      "| 66|          6.7|         3.1|          4.4|         1.4|Iris-versicolor|\n",
      "| 67|          5.6|         3.0|          4.5|         1.5|Iris-versicolor|\n",
      "| 68|          5.8|         2.7|          4.1|         1.0|Iris-versicolor|\n",
      "| 69|          6.2|         2.2|          4.5|         1.5|Iris-versicolor|\n",
      "| 70|          5.6|         2.5|          3.9|         1.1|Iris-versicolor|\n",
      "+---+-------------+------------+-------------+------------+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for table in tables:\n",
    "    table.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6a399287",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.45722781639411325 0.3221082159003181 Column<'Species'>\n",
      "0.7467803732639264 0.30630821115803564 Column<'Species'>\n",
      "0.5259107172828247 0.786668088522817 Column<'Species'>\n"
     ]
    }
   ],
   "source": [
    "for df in tables:\n",
    "    print(df.stat.corr('SepalLengthCm','SepalWidthCm'),df.stat.corr('PetalLengthCm','PetalWidthCm'),df.Species)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92162218",
   "metadata": {},
   "source": [
    "### New Work\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "879869a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 15:>                                                         (0 + 1) / 1]\r",
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+------+\n",
      "|   name|gender|salary|\n",
      "+-------+------+------+\n",
      "|  James|     M| 60000|\n",
      "|Michael|     M| 70000|\n",
      "| Robert|  null|400000|\n",
      "|  Maria|     F|500000|\n",
      "|    Jen|      |  null|\n",
      "+-------+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = [(\"James\",\"M\",60000),(\"Michael\",\"M\",70000),\n",
    "        (\"Robert\",None,400000),(\"Maria\",\"F\",500000),\n",
    "        (\"Jen\",\"\",None)]\n",
    "\n",
    "columns = [\"name\",\"gender\",\"salary\"]\n",
    "df = spark.createDataFrame(data = data, schema = columns)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "45ac523c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+------+----------+\n",
      "|   name|gender|salary|new_gender|\n",
      "+-------+------+------+----------+\n",
      "|  James|     M| 60000|      Male|\n",
      "|Michael|     M| 70000|      Male|\n",
      "| Robert|  null|400000|          |\n",
      "|  Maria|     F|500000|    Female|\n",
      "|    Jen|      |  null|          |\n",
      "+-------+------+------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2 = df.withColumn(\"new_gender\", F.when(df.gender == \"M\", \"Male\").when(df.gender == \"F\", \"Female\").when(df.gender.isNull(), \"\").otherwise(df.gender))\n",
    "df2.show()\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "eaf837f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+------+----------+\n",
      "|name   |gender|salary|new_gender|\n",
      "+-------+------+------+----------+\n",
      "|James  |M     |60000 |Male      |\n",
      "|Michael|M     |70000 |Male      |\n",
      "|Robert |null  |400000|          |\n",
      "|Maria  |F     |500000|Female    |\n",
      "|Jen    |      |null  |          |\n",
      "+-------+------+------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df3 = df.withColumn(\"new_gender\", F.expr(\"CASE WHEN gender = 'M' THEN 'Male' \" + \n",
    "               \"WHEN gender = 'F' THEN 'Female' WHEN gender IS NULL THEN ''\" +\n",
    "               \"ELSE gender END\"))\n",
    "df3.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "65850f79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+----------+\n",
      "|EmpId|Salary|lit_value1|\n",
      "+-----+------+----------+\n",
      "|111  |50000 |1         |\n",
      "|222  |60000 |1         |\n",
      "|333  |40000 |1         |\n",
      "+-----+------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#  when(condition, do x).otherwise(y)\n",
    "\n",
    "data = [(\"111\",50000),(\"222\",60000),(\"333\",40000)]\n",
    "columns= [\"EmpId\",\"Salary\"]\n",
    "df = spark.createDataFrame(data = data, schema = columns)\n",
    "df2 = df.select(col(\"EmpId\"),col(\"Salary\"),lit(\"1\").alias(\"lit_value1\"))\n",
    "df2.show(truncate=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d28090ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df3 = df2.withColumn(\"lit_value2\", when(col(\"Salary\") >= 40000 & col(\"Salary\")  < 50000, lit(\"100\")).otherwise(lit(\"200\")))\n",
    "df3 = df2.withColumn(\"lit_value2\", when((col(\"Salary\") >=40000) & (col(\"Salary\") <= 50000),lit(\"100\")).otherwise(lit(\"200\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "fc3b0f13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+----------+----------+\n",
      "|EmpId|Salary|lit_value1|lit_value2|\n",
      "+-----+------+----------+----------+\n",
      "|  111| 50000|         1|       100|\n",
      "|  222| 60000|         1|       200|\n",
      "|  333| 40000|         1|       100|\n",
      "+-----+------+----------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df3.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "245a6947",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- name: string (nullable = true)\n",
      " |-- languagesAtSchool: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- currentState: string (nullable = true)\n",
      "\n",
      "+----------------+------------------+------------+\n",
      "|name            |languagesAtSchool |currentState|\n",
      "+----------------+------------------+------------+\n",
      "|James,,Smith    |[Java, Scala, C++]|CA          |\n",
      "|Michael,Rose,   |[Spark, Java, C++]|NJ          |\n",
      "|Robert,,Williams|[CSharp, VB]      |NV          |\n",
      "+----------------+------------------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#  df.select(split(df.name,',').alias(\"nameArray\")).drop(\"name\")\n",
    "# string to array_of_string -> split *using delimiter*\n",
    "# array to string -> concat_ws\n",
    "#  Note -> use 'col()' as it takes in col argument in second\n",
    "columns = [\"name\",\"languagesAtSchool\",\"currentState\"]\n",
    "data = [(\"James,,Smith\",[\"Java\",\"Scala\",\"C++\"],\"CA\"), \\\n",
    "    (\"Michael,Rose,\",[\"Spark\",\"Java\",\"C++\"],\"NJ\"), \\\n",
    "    (\"Robert,,Williams\",[\"CSharp\",\"VB\"],\"NV\")]\n",
    "\n",
    "df = spark.createDataFrame(data=data,schema=columns)\n",
    "df.printSchema()\n",
    "df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9db0c6b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.withColumn(\"Column_Array\", concat_ws(\" \",col(\"languagesAtSchool\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c7ea1dad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+------------------+------------+--------------+\n",
      "|            name| languagesAtSchool|currentState|  Column_Array|\n",
      "+----------------+------------------+------------+--------------+\n",
      "|    James,,Smith|[Java, Scala, C++]|          CA|Java Scala C++|\n",
      "|   Michael,Rose,|[Spark, Java, C++]|          NJ|Spark Java C++|\n",
      "|Robert,,Williams|      [CSharp, VB]|          NV|     CSharp VB|\n",
      "+----------------+------------------+------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1679afcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  regex replace ->. regex replace(name of column , string value to be replaced, string value to replace by )\n",
    "#  there is overlay as well\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1c1203aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------------+\n",
      "|Seqno|Name        |\n",
      "+-----+------------+\n",
      "|1    |john jones  |\n",
      "|2    |tracey smith|\n",
      "|3    |amy sanders |\n",
      "+-----+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import StringType\n",
    "\n",
    "columns = [\"Seqno\",\"Name\"]\n",
    "data = [(\"1\", \"john jones\"),\n",
    "    (\"2\", \"tracey smith\"),\n",
    "    (\"3\", \"amy sanders\")]\n",
    "\n",
    "df = spark.createDataFrame(data=data,schema=columns)\n",
    "df.show(truncate=False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ec595a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertCase(str):\n",
    "    resStr=\"\"\n",
    "    arr = str.split(\" \")\n",
    "    for x in arr:\n",
    "       resStr= resStr + x[0:1].upper() + x[1:len(x)] + \" \"\n",
    "    return resStr "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e896154f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Converting function to UDF \"\"\"\n",
    "convertUDF = udf(lambda z: convertCase(z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9aea9b5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------------+\n",
      "|Seqno|Name         |\n",
      "+-----+-------------+\n",
      "|1    |John Jones   |\n",
      "|2    |Tracey Smith |\n",
      "|3    |Amy Sanders  |\n",
      "+-----+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(col(\"Seqno\"), \\\n",
    "    convertUDF(col(\"Name\")).alias(\"Name\") ) \\\n",
    ".show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9bac5e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def upperCase(str):\n",
    "    return str.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5b3e8738",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------------+-------------+\n",
      "|Seqno|Name        |Cureated Name|\n",
      "+-----+------------+-------------+\n",
      "|1    |john jones  |JOHN JONES   |\n",
      "|2    |tracey smith|TRACEY SMITH |\n",
      "|3    |amy sanders |AMY SANDERS  |\n",
      "+-----+------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "upperCaseUDF = udf(lambda z:upperCase(z),StringType())    \n",
    "\n",
    "df.withColumn(\"Cureated Name\", upperCaseUDF(col(\"Name\"))) \\\n",
    ".show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71aaaea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Using UDF on SQL \"\"\"\n",
    "spark.udf.register(\"convertUDF\", convertCase,StringType())\n",
    "df.createOrReplaceTempView(\"NAME_TABLE\")\n",
    "spark.sql(\"select Seqno, convertUDF(Name) as Name from NAME_TABLE\") \\\n",
    "     .show(truncate=False)\n",
    "     \n",
    "spark.sql(\"select Seqno, convertUDF(Name) as Name from NAME_TABLE \" + \\\n",
    "          \"where Name is not null and convertUDF(Name) like '%John%'\") \\\n",
    "     .show(truncate=False)  \n",
    "     \n",
    "\"\"\" null check \"\"\"\n",
    "\n",
    "columns = [\"Seqno\",\"Name\"]\n",
    "data = [(\"1\", \"john jones\"),\n",
    "    (\"2\", \"tracey smith\"),\n",
    "    (\"3\", \"amy sanders\"),\n",
    "    ('4',None)]\n",
    "\n",
    "df2 = spark.createDataFrame(data=data,schema=columns)\n",
    "df2.show(truncate=False)\n",
    "df2.createOrReplaceTempView(\"NAME_TABLE2\")\n",
    "    \n",
    "spark.udf.register(\"_nullsafeUDF\", lambda str: convertCase(str) if not str is None else \"\" , StringType())\n",
    "\n",
    "spark.sql(\"select _nullsafeUDF(Name) from NAME_TABLE2\") \\\n",
    "     .show(truncate=False)\n",
    "\n",
    "spark.sql(\"select Seqno, _nullsafeUDF(Name) as Name from NAME_TABLE2 \" + \\\n",
    "          \" where Name is not null and _nullsafeUDF(Name) like '%John%'\") \\\n",
    "     .show(truncate=False)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b8b9f39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ca0e11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d459237",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
